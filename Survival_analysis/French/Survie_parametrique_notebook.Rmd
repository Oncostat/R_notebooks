---
title: "Modèles de survie paramétriques"
output:
  html_document: 
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_notebook: default
  pdf_document: default
---

Ceci est un "notebook". Il permet d'écrire du code au milieu du texte et d'afficher son résultat lorsque le document est compilé. Vous pouvez également utiliser les icones en haut à droite de chaque "chunk" (partie où se trouve le code), par exemple, la flèche verte permet de ne recompiler que cette partie.

Ce document est écrit en language markdown. Les bases qui vous permettront de comprendre la sytaxe sont juste que le "#" permet de définir le niveau du titre ("#" = titre 1; "##" = titre 1.1; "###" = titre 1.1.1;...). Le code R est écrit entre 2 balises, une d'ouverture du chunk et une de fermeture. Exemple:

```{r}
head(cars)
```

Le résultat du code s'affiche en dessous si vous compilez le document, ou juste ce chunck en cliquant sur la flèche verte.

Finalement, lorsque votre document est terminé, vous pouvez obtenir une version clean en cliquant sur le bouton "preview" ou en tapant *Ctrl+Shift+K*. Un fichier de type html se trouve maintenant à côté de votre fichier Rmd, que vous pouvez garder pour vous ou envoyer à quelqu'un, il suffit d'un navigateur internet (même sans connexion) pour pouvoir l'afficher.


**! Note : !** en cas de symbole étrange dans les phrases du notebook, cela indique un problème d'encodage. Pour résoudre le problème `Tools > Global Options > Code > Saving ; Choisir iso-8859-1 ; Fermer et rouvrez votre RStudio`. Si vous souhaitez plus tard le compilez en pdf ou en HTML il faudra l'enregistrer en UFT-8 `File > Save with Encoding ... > UTF-8`

Revenons maintenant au cours...



# Pourquoi utiliser un modèle paramétrique ?

L'utilisation de modèles non-paramétrique ou semi-paramétrique (ex : Cox) présentent de nombreux avantages, mais également de nombreuses limites du fait de l'absence d'une forme structurée. En effet, le risque de base estimé par ces modèles est très fidèles aux données, mais trop pour pouvoir extrapoler à de nouvelles données.

Mais à quoi cela ressemble-t-il ?   
Prenons exemple de la distribution de Weibull :

```{r}
library(survival)
pts <- 0:100/30
sc <- 2
sh <- 1.5
XLAB = 'Temps (t)'
N <- 100
set.seed(1)
times <- rweibull(N, sh, sc)
event <- rep(1, N)
par(mfrow=c(1, 3), mar = c(5, 5, 2, 2) + .1, bty='l')
plot(survfit(Surv(times, event) ~ 1), ylim=0:1,main = 'Probabilité de survie\nS(t) = P(T > t)',ylab = '',xlab = XLAB, lwd=2, col='red', xmax = max(pts), conf.int = FALSE)
plot(0,0, ty='l',ylim=0:1,main = 'Densité de probabilité\nf(t) = -dS(t) / dt',ylab = '', xlab = XLAB, lwd=2, col='white')
text(0,0.5,"?",cex=10)
plot(0,0, ty='l',ylim=0:1,main = 'Risque instantané\nh(t) = f(t) / S(t)',ylab = '', xlab = XLAB, lwd=2, col='white')
text(0,0.5,"?",cex=10)

```


Sur le premier plot de la figure, à chaque temps t, la pente de cette fonction est égale à 0 lorsqu'il n'y a pas d'évènement et à $\infty$ lorsqu'il y a un évènement.   
Lorsque l'on dérive cette distribution de survie, on a une nouvelle distribution (2nd graphique) où chaque trait vertical correspond à une densité allant vers $\infty$ (car 1/0=$\infty$) :

```{r}
par(mfrow=c(1, 3), mar = c(5, 5, 2, 2) + .1, bty='l')
plot(survfit(Surv(times, event) ~ 1), ylim=0:1,main = 'Probabilité de survie\nS(t) = P(T > t)',ylab = '',xlab = XLAB, lwd=2, col='red', xmax = max(pts), conf.int = FALSE)
plot(times[event==1],rep(0,sum(event)),ylim=0:1,main = 'Densité de probabilité\nf(t) = -dS(t) / dt',ylab = '', xlab = XLAB, lwd=2, col='red')
legend("topright","Event times",pch=1,col='red',bty="n")
abline(v=times[event==1],col="grey")
plot(0,0, ty='l',ylim=0:1,main = 'Risque instantané\nh(t) = f(t) / S(t)',ylab = '', xlab = XLAB, lwd=2, col='white')
text(0,0.5,"?",cex=10)

```

La fonction de risque instanané est donc défini également de la sorte :

```{r}
par(mfrow=c(1, 3), mar = c(5, 5, 2, 2) + .1, bty='l')
plot(survfit(Surv(times, event) ~ 1), ylim=0:1,main = 'Probabilité de survie\nS(t) = P(T > t)',ylab = '',xlab = XLAB, lwd=2, col='red', xmax = max(pts), conf.int = FALSE)
plot(times[event==1],rep(0,sum(event)),ylim=0:1,main = 'Densité de probabilité\nf(t) = -dS(t) / dt',ylab = '', xlab = XLAB, lwd=2, col='red')
legend("topright","Event times",pch=1,col='red',bty="n")
abline(v=times[event==1],col="grey")
plot(times[event==1],rep(0,sum(event)),ylim=0:1,main = 'Risque instantané\nh(t) = f(t) / S(t)',ylab = '', xlab = XLAB, lwd=2, col='red')
legend("topright","Event times",pch=1,col='red',bty="n")
abline(v=times[event==1],col="grey")

```




**Dans un autre contexte**, prenons les poids de souris mesurés lors d'une expérience. Nous connaissons leur distribution, elle suit une loi normale.  
Utiliser une méthode non-paramétrique similaire reviendrait à avoir une distribution telle que celle-ci :

```{r}
N <- 50
set.seed(1)
x <- rnorm(N,20,7.5)
plot(x,rep(0,length(x)),ylim=0:1,main = 'Densité de probabilité',ylab = '', xlab = "Mouse weight (g)", lwd=2, col='red',bty='l')
legend("topright","Observations",pch=1,col='red',bty="n")
abline(v=x,col="grey")

```

Il est impossible de faire des prédictions de nouvelles observations à partir de cette distribution. De ce fait, il est courant de placer une densité de probabilité sur ces points, représentant leur densité/concentration (forme que l'on connait) :

```{r}
plot(x,rep(0,length(x)),ylim=c(0,0.1),main = 'Densité de probabilité',ylab = '', xlab = "Mouse weight (g)", lwd=2, col='red',bty='l')
legend("topright","Observations",pch=1,col='red',bty="n")
abline(v=x,col="grey")
curve(dnorm(x,20,7.5),add=T,lwd=2,col='red')
```


Ici, on place un modèle gaussien sur les poids des souris. **A partir de ce modèle, nous pouvons** :

- calculer facilement des statistiques correspondantes à ces distributions (moyenne, médiane,...) grâce aux formules analytiques
- faire de la prédiction de temps de survie
- extrapoler les résultats en dehors des limites de l'échantillon (au delà du dernier temps observé)
- réaliser des études de simulations en tirant au hasard des valeurs dans cette distribution pour créer une population "synthétique" (souvent utilisée pour, entre autre, faire du calcul de taille d'échantillon, tester les performances d'un modèle et/ou sa robustesse aux écart à ses hypothèses,...)

Cela permet également de restreindre le modèle pour limiter le sur-apprentissage, i.e. permettre d'avoir un modèle qui pourra extrapoler au delà de sa population d'apprentissage (cf cours modèles prédictifs).




**Pour revenir à la survie**, nous aurons une fonction de survie plus lisse qu'un estimateur non-paramétrique et nous pouvons définir la densité de probabilité et la fonction de risque instantané :

```{r}
pts <- 0:100/30
sc <- 2
sh <- 1.5
XLAB = 'Temps (t)'
#par(xaxs='i', mfrow=c(1, 3), bty='l')
par( mfrow=c(1, 3), bty='l')
plot(pts, pweibull(pts, sh, sc, lower.tail = FALSE), ty='l', ylim=0:1,main = 'Probabilité de survie\nS(t) = P(T > t)',ylab = '', xlab = XLAB, lwd=2, col='red')
plot(pts, dweibull(pts, sh, sc), ty='l',main = 'Densité de probabilité\nf(t) = -dS(t) / dt',ylab = '', xlab = XLAB, lwd=2, col='red')
plot(pts, dweibull(pts, sh, sc) / pweibull(pts, sh, sc, lower.tail = FALSE),ty='l', main = 'Risque instantané\nh(t) = f(t) / S(t)',ylab = '', xlab = XLAB, lwd=2, col='red')

```




# Dataset

Pour cette partie du TP, nous utiliserons le data "kidney" disponible dans le package survival.

```{r}
library('survival')
data('kidney')
head(kidney)
```

La variable `sex` sera considérée comme variable explicative lors de ce TP. C'est une variable binaire, codé par "1" et "2", et non par "0" et "1", il faudra donc être vigilent sur l'écriture du programme pour ne pas considérer cette valeur comme une variable continue. Recodons la tout de suite pour éviter la confusion :

```{r}
kidney$sex=kidney$sex-1
```




# Distributions de survie paramétriques

## Récapitulatif

Dans ce TP, nous utiliserons les paraméterisations du package survival qui correspondent également à celle que vous pourrez rtetrouver dans certains documents, y compris les pages wikipedia de ces distributions. Afin de ne pas vous perdre, le tableau ci-dessous fait compare les fonctions de survie associées par rapport à celles que vous avez pu voir en cours.


| Famille          | Package survival | Cours            |
|------------------|------------------|------------------|
| Exponentielle    |$\exp(- \lambda t)$|$\exp(- \lambda t)$|
| Weibull          |$\exp(- (\frac{t}{\lambda})^{\frac{1}{\sigma}})$|$\exp(-(\lambda t)^\frac{1}{\sigma})$|
| Log-normal       |$1 - \Phi\left(\frac{\ln(t)-\mu}\sigma \right)$| - |
| Log-logistique   |$\frac{1}{1+\exp(\frac{\ln(t) - \mu)}{\sigma})}$| $\frac{1}{1+(\lambda t)^{\gamma}}$                  |
Là où les paramètres de forme (shape, $\sigma$) vont quantifier la dispersion de la distribution, les paramètres d'échelle (scale, $\lambda$ et $\mu$) vont être ceux correspondant au mode de la distribution, et donc être les plus pertinents pour caractériser la survie (c'est sur ce paramètre que seront posés les coefficients de régression, cf ci-dessous).

**L'interprétation** des paramètres d'échelle (scale, $\lambda$ et $\mu$) est la suivante :
- pour la régression exponentielle, plus $\lambda$ augmente, plus la survie attendue à $t$ est faible
- pour la régression de Weibull, plus $\lambda$ augmente, plus la survie attendue à $t$ est élevée selon la paraméterisation du package survival. Il faut donc inverser sont raisonnement par rapport à la distribution exponentielle
- pour les régression Log-normal et Log-logistique, plus $\mu$ augmente, plus la survie attendue à $t$ est faible.

**Pour les modèles de regression**, le(s) paramètre(s) $\lambda$ et $\mu$ résultent de l'exponentielle d'une combinaison linéaires des variables, c'est-à-dire : $\lambda=\exp(-(\beta_0+\beta_1 X1 +\beta_2 X2 +...+\beta_p Xp))$. Ce sont les coefficients de regression $\beta$ qui sont fournis par la sortie des fonctions de R. **Leur interprétation** dépend donc de leur signe, mais également de la forme de la fonction de survie et est détaillée dans les paragraphes ci-dessous.

<!-- **Non-Correspondance avec le Cox** Si dans le modèle de Cox un coefficient positif correspond à une augmentation du taux de décès (négatif), dans les modèles AFT un coefficient positif correspond à une augmention de la survie (positif) où on aura alors un moins dans l'exponentiel tel que $\lambda = e^{-(\beta_0 + \beta_1 * X_1 + \beta_2 * X_2 ...)}$. -->


## Estimation des paramètres

Dans cette section, les codes de base pour utiliser les différentes régression sont présentées, ainsi que l'interprétations de leurs sorties. *Pour résumer l'interprétation des coefficients*, un coefficient associé à une variable explicative $>0$ implique une augmentation de la probabilité de survie à chaque temps $t$, et réciproquement.

### Modèle exponentiel

#### Distribution exponentielle

Dans le cadre du modèle exponentiel, on a $S(t)=\exp(- \lambda t)$. Plus $\lambda$ augmente, plus la survie attendue est faible. Même si les formules analytiques existent, nous pouvons aussi calculer son paramètre avec la fonction `survreg` du package `survival` de la façon suivante :

```{r}
fit_exp<-survreg(Surv(time,status) ~ 1, kidney,dist="exponential")
summary(fit_exp)
```

Ici, l'`intercept` est celui de la régression exponentielle, c'est-à-dire, lorsque l'on considère $\lambda=\exp(\beta_0)$, donc $S(t)=\exp(- \exp(-\beta_0) t)$. Plus $\beta_0$ augmente, plus $\lambda$ diminue, plus la survie attendue est élevée. Nous pouvons retrouver notre $\lambda$ à partir de l'objet `survfit` par :

```{r}
(beta0_exp<-fit_exp$coef) #extraction de la valeur de beta0
(lambda_exp<-exp(-beta0_exp))
```


#### Régression exponentielle

La régression exponentielle multivariable considère $\lambda = \exp(-(\beta_0 + \beta_1 * X_1 + \beta_2 * X_2+ ...+X_p))$, correspondant à la fonction de survie $S(t) =\exp(- e^{-(\beta_0 + \beta_1 * X_1 + \beta_2 * X_2+ ...+X_p)} t)$. En reprenant l'exemple précédent, ajustons le modèle pour la variable `sex` :

```{r}
fit_exp2<-survreg(Surv(time,status) ~ sex, kidney,dist="exponential")
summary(fit_exp)
```

Ce modèle correspond à $\lambda = \exp(-(\beta_0 + \beta_1 * sex))$ et $S(t)=\exp(- exp(\beta_0 + \beta_1 * sex)) t)$. Comme précédemment, plus $\beta_0+ \beta_1 * sex$ augmente, plus $\lambda$ diminue, plus la survie attendue est élevée. Comme $\beta_1=0.40$, $\beta_0+ \beta_1 * sex$ est plus élevé chez les femmes (précédemment re-codées 1 vs hommes re-codés 0), la survie attendue chez les femmes est donc plus élevée que chez les hommes.
Vérifions cela d'après les formules précédentes :

```{r}
betas_exp<-fit_exp2$coef #extraction de la valeur des betas
exp(-exp(-betas_exp[1])) #Survie chez les hommes
exp(-exp(-sum(betas_exp))) #survie chez les femmes
```

Pour une variable continue, un $\beta_1>0$ indiquerait une diminution de la survie avec les valeurs de cette variable. Cette interprétation est donc l'inverse de celle des coefficients du modèle de Cox.






### Modèle de Weibull

#### Distribution de Weibull

Dans le cadre du modèle de Weibull, la fonction `survreg` considère la paraméterisation $S(t)=\exp(- (\frac{t}{\lambda})^{\frac{1}{\sigma}})$. A l'inverse du modèle exponentiel, plus $\lambda$ augmente, plus la survie attendue est faible. Nous pouvons calculer ses paramètres de `scale` et `shape` avec la fonction `survreg` du package `survival` de la façon suivante :

```{r}
fit_weib<-survreg(Surv(time,status) ~ 1, kidney,dist="weibull")
summary(fit_weib)
```

L'intercept correspond comme précédemment à celui de la régression sur $\lambda$, c'est-à-dire, $\lambda=exp(\beta_0)$, correspondant à la fonction de survie $S(t)=\exp(- (\frac{t}{exp(\beta_0)})^{\frac{1}{\sigma}})$. 
Plus $\beta_0$ augmente, plus $\lambda$ augmente, plus la survie attendue est élevée. Pourquoi cette relation (augmentation de $\beta_0$ $=$ augmentation de la survie) est similaire au modèle exponentiel malgrès l'absence de "-" dans l'exponentielle ? Ceci est due à une des propriété de base de la fonction exponentielle : $\frac{1}{\exp(x)}=\exp(-x)$. Pour simplifier, si $\sigma=1$, on a $\frac{1}{\lambda_{Weibull}}=\frac{1}{\beta0}=\exp(-\beta0)=\lambda_{exponentiel}$. Nous pouvons retrouver notre $\lambda$ (et notre $\sigma$) à partir de l'objet `survfit` par :

```{r}
beta0_weib<-fit_weib$coef #extraction de la valeur de beta0
(lambda_weib<-exp(beta0_weib))
(scale_weib<-fit_weib$scale)
```



#### Régression de Weibull

De façon similaire à la régression de Weibull multivariable considère $\lambda = \exp(-(\beta_0 + \beta_1 * X_1 + \beta_2 * X_2+ ...+X_p))$. En reprenant l'exemple précédent, ajustons le modèle pour la variable `sex` :


```{r}
fit_weib2<-survreg(Surv(time,status) ~ sex, kidney,dist="weibull")
summary(fit_weib2)
```


Ce modèle correspond à $\lambda = \exp(-(\beta_0 + \beta_1 * sex))$ et $S(t)=\exp(- (\frac{t}{exp(\beta_0+ \beta_1 * sex)})^{\frac{1}{\sigma}})$. Nous pouvons retrouver $\lambda$ et $\sigma$ facilement à partir de l'objet `survfit`:

```{r}
betas_weib<-fit_weib2$coef #extraction de la valeur des betas
lambda_weib2<-exp(betas_weib)
scale_weib2<-fit_weib2$scale
```

Comme précédemment, plus $\beta_0+ \beta_1 * sex$ augmente, plus $\lambda$ augmente, plus la survie attendue est élevée. Comme $\beta_1=2.68$, $\beta_0+ \beta_1 * sex$ est plus élevé chez les femmes, la survie attendue chez les femmes est donc plus élevée que chez les hommes.
Vérifions cela d'après les formules précédentes :

```{r}
betas_weib<-fit_weib2$coef #extraction de la valeur des betas
exp(-(1/betas_exp[1])^(1/scale_weib2)) #Survie chez les hommes
exp(-(1/sum(betas_exp))^(1/scale_weib2)) #survie chez les femmes
```

Comme précédemment, pour une variable continue, un $\beta_1>0$ indiquerait une diminution de la survie avec les valeurs de cette variable.









### Modèle log-normale


#### Distribution log-normale

Dans le cadre du modèle de log-normale, la fonction `survreg` considère la paraméterisation $S(t) = 1 - \Phi\left(\frac{\ln(t)-\mu}\sigma \right)$. Plus $\mu$ augmente, plus la survie attendue sera élevée. Nous pouvons calculer ses paramètres avec la fonction `survreg` du package `survival` de la façon suivante :

```{r}
fit_logNorm<-survreg(Surv(time,status) ~ 1, kidney,dist="lognormal")
summary(fit_logNorm)
```

L'intercept correspond comme précédemment à celui de la régression sur $\mu$, c'est-à-dire, $\mu=\beta_0$, correspondant à la fonction de survie $S(t) = 1 - \Phi\left(\frac{\ln(t)-\beta_0}\sigma \right)$. The `log(scale)` correspond à $\sigma$.
Plus $\beta_0$ augmente, plus $\mu$ augmente, plus la survie attendue est élevée. Nous pouvons retrouver notre $\mu$ (et notre $\sigma$) à partir de l'objet `survfit` par :

```{r}
mu_logNorm<-fit_logNorm$coef
scale_logNorm<-fit_logNorm$scale
```



#### Régression log-normale

La régression log-normale multivariable considère $\mu = \beta_0 + \beta_1 * X_1 + \beta_2 * X_2+ ...+X_p$. En reprenant l'exemple précédent, ajustons le modèle pour la variable `sex` :

```{r}
fit_logNorm2<-survreg(Surv(time,status) ~ sex, kidney,dist="lognormal")
summary(fit_logNorm2)
```

Nous pouvons extraire facilement ces paramètres depuis  l'objet `survfit` :

```{r}
mu_logNorm2<-fit_logNorm2$coef
scale_logNorm2<-fit_logNorm2$scale
```


Ce modèle correspond à $\mu = \beta_0 + \beta_1 * sex$ et $S(t) = 1 - \Phi\left(\frac{\ln(t)-(\beta_0 + \beta_1 * sex)}\sigma \right)$. Comme précédemment, plus $\beta_0+ \beta_1 * sex$ augmente, plus $\mu$ augmente, plus la survie attendue est élevée. Comme $\beta_1=1.37$, $\beta_0+ \beta_1 * sex$ est plus élevé chez les femmes, la survie attendue chez les femmes est donc plus élevée que chez les hommes.
Vérifions cela d'après les formules précédentes :

```{r}
1-pnorm((log(1)-mu_logNorm2[1])/scale_logNorm2) #Survie chez les hommes
1-pnorm((log(1)-sum(mu_logNorm2))/scale_logNorm2) #survie chez les femmes
```

Comme précédemment, pour une variable continue, un $\beta_1>0$ indiquerait une diminution de la survie avec les valeurs de cette variable.




### Modèle log-logistique


#### Distribution log-logistique

Dans le cadre du modèle de log-logistique, la fonction `survreg` considère la paraméterisation $S(t) = \frac{1}{1+\exp(\frac{\ln(t) - \mu)}{\sigma})}$. Plus $\mu$ augmente, plus la survie attendue sera élevée. Nous pouvons calculer ses paramètres avec la fonction `survreg` du package `survival` de la façon suivante :

```{r}
fit_logLogi<-survreg(Surv(time,status) ~ 1, kidney,dist="loglogistic")
summary(fit_logLogi)
```

L'intercept correspond comme précédemment à celui de la régression sur $\mu$, c'est-à-dire, $\mu=\beta_0$, correspondant à la fonction de survie $S(t) = \frac{1}{1+\exp(\frac{\ln(t) - \beta_0)}{\sigma})}$. The `log(scale)` correspond à $\sigma$.
Plus $\beta_0$ augmente, plus $\mu$ augmente, plus la survie attendue est élevée. Nous pouvons retrouver notre $\mu$ (et notre $\sigma$) à partir de l'objet `survfit` par :

```{r}
mu_logLogi<-fit_logLogi$coef
scale_logLogi<-fit_logLogi$scale
```



#### Régression log-logistique

La régression log-logistique multivariable considère $\mu = \beta_0 + \beta_1 * X_1 + \beta_2 * X_2+ ...+X_p$. En reprenant l'exemple précédent, ajustons le modèle pour la variable `sex` :

```{r}
fit_logLogi2<-survreg(Surv(time,status) ~ sex, kidney,dist="loglogistic")
```

Nous pouvons extraire facilement ces paramètres depuis  l'objet `survfit` :

```{r}
mu_logLogi2<-fit_logLogi2$coef
scale_logLogi2<-fit_logLogi2$scale
```


Ce modèle correspond à $\mu = \beta_0 + \beta_1 * sex$ et $S(t) = \frac{1}{1+\exp(\frac{\ln(t) - (\beta_0 + \beta_1 * sex))}{\sigma})}$. Comme précédemment, plus $\beta_0+ \beta_1 * sex$ augmente, plus $\mu$ augmente, plus la survie attendue est élevée. Comme $\beta_1=1.52$, $\beta_0+ \beta_1 * sex$ est plus élevé chez les femmes, la survie attendue chez les femmes est donc plus élevée que chez les hommes.
Vérifions cela d'après les formules précédentes :

```{r}
1/(1+exp((log(1)-mu_logLogi2[1])/scale_logLogi2)) #Survie chez les hommes
1/(1+exp((log(1)-sum(mu_logLogi2))/scale_logLogi2)) #survie chez les femmes
```

Comme précédemment, pour une variable continue, un $\beta_1>0$ indiquerait une diminution de la survie avec les valeurs de cette variable.



### Représentations graphiques

#### Sans variable explicative


```{r}
par(mar = c(4, 4, .5, 0) + .1)
plot(survfit(Surv(time, status) ~ 1, data = kidney), conf.int = FALSE, xlab = 'Temps, t',ylab = bquote(paste(S(t))), col = "black")
curve(exp(-lambda_exp*x),add=T,col='red')
curve(exp(-(x/lambda_weib)^(1/scale_weib)),add=T,col="green")
curve(1-pnorm((log(x)-mu_logNorm)/scale_logNorm),add=T,col="blue")
curve(1/(1+exp((log(x)-mu_logLogi)/scale_logLogi)),add=T,col="cyan")
legend("topright",c("Exponential","Weibull","Log normal","Log logistic"),col=c("red","green","blue","cyan"),lty=1,bty="n")
```



#### Ajustement sur le sexe

```{r}
par(mar = c(4, 4, .5, 0) + .1)
plot(survfit(Surv(time, status) ~ sex, data = kidney), conf.int = FALSE, xlab = 'Temps, t',ylab = bquote(paste(S(t))), col = "black", lty = c(1,2))

curve(exp(-exp(-betas_exp[1])*x),add=T,col='red')
curve(exp(-exp(-sum(betas_exp))*x),add=T,col='red', lty=2)

curve(exp(-(x/exp(+betas_weib[1]))^(1/scale_weib2)),add=T,col="green")
curve(exp(-(x/exp(sum(betas_weib)))^(1/scale_weib2)),add=T,col="green", lty=2)

curve(1-pnorm((log(x)-mu_logNorm2[1])/scale_logNorm2),add=T,col="blue")
curve(1-pnorm((log(x)-sum(mu_logNorm2))/scale_logNorm2),add=T,col="blue", lty=2)

curve(1/(1+exp((log(x)-mu_logLogi2[1])/scale_logLogi2)),add=T,col="cyan")
curve(1/(1+exp((log(x)-sum(mu_logLogi2))/scale_logLogi2)),add=T,col="cyan", lty=2)

legend("topright",c(paste("Hommes",c("Exponential","Weibull","Log normal","Log logistic")),
                    paste("Femmes",c("Exponential","Weibull","Log normal","Log logistic")  )), col=rep(c("red","green","blue","cyan"),2), lty=c(rep(1,4),rep(2,4)),bty="n")
```



## Médiane de survie (Utilisation de l'estimation avec l'intercept uniquement)

L'avantage d'avoir une distribution paramétrique et que nous avons des solutions analytiques qui nous permettent d'obtenir des statistiques facilement à partir de quelques formules bien connues (moyenne,...).
La médiane de survie s'obtient facilement à partir de la fonction de répartition. Sous R, les fonctions des distribution usuelles peuvent être utilisée :
```{r}
qexp(0.5,lambda_exp)
qweibull(0.5,1/scale_weib,lambda_weib)
qlnorm(0.5,mu_logNorm,scale_logNorm)
```
(Pour la log-logistique, d'autres packages sont nécessaires, ex : `flexsurv`)

On peut vérifier sur le plot :

```{r}
par(mar = c(4, 4, .5, 0) + .1)
plot(survfit(Surv(time, status) ~ 1, data = kidney), conf.int = FALSE, xlab = 'Temps, t',ylab = bquote(paste(S(t))), col = "black")
curve(exp(-lambda_exp*x),add=T,col='red')
curve(exp(-(x/lambda_weib)^(1/scale_weib)),add=T,col="green")
curve(1-pnorm((log(x)-mu_logNorm)/scale_logNorm),add=T,col="blue")
curve(1/(1+exp((log(x)-mu_logLogi)/scale_logLogi)),add=T,col="cyan")
legend("topright",c("Exponential","Weibull","Log normal","Log logistic"),col=c("red","green","blue","cyan"),lty=1,bty="n")
abline(h=0.5,col="gray")
abline(v=c(qexp(0.5,lambda_exp),qweibull(0.5,1/scale_weib,lambda_weib),qlnorm(0.5,mu_logNorm,scale_logNorm)),col=2:4)

```




## Extrapolation


```{r}
par(mar = c(4, 4, .5, 0) + .1)
plot(survfit(Surv(time, status) ~ 1, data = kidney),xlim=c(0,1000), conf.int = FALSE, xlab = 'Temps, t',ylab = bquote(paste(S(t))), col = "black")
curve(exp(-lambda_exp*x),add=T,col='red')
curve(exp(-(x/lambda_weib)^(1/scale_weib)),add=T,col="green")
curve(1-pnorm((log(x)-mu_logNorm)/scale_logNorm),add=T,col="blue")
curve(1/(1+exp((log(x)-mu_logLogi)/scale_logLogi)),add=T,col="cyan")
legend("topright",c("Exponential","Weibull","Log normal","Log logistic"),col=c("red","green","blue","cyan"),lty=1,bty="n")

```





## Prédiction

Réalisons des prédictions pour nos observations :

```{r}
predict(fit_weib)
```

On peut constater que la moyenne de la distribution de Weibull est assigné à toutes les observations. Ces valeurs seront modifiées en fonction des facteurs d'ajustement pris en compte dans le modèle. Ex :

```{r}
fit_weib2<-survreg(Surv(time,status) ~ sex, kidney,dist="weibull")
#summary(fit_weib2)
#prediction pour sex = 1
print(paste0("Prédiction pour les hommes : ",predict(fit_weib2,newdata = list(sex=0))))
#prediction pour sex = 2
print(paste0("Prédiction pour les femmes : ",predict(fit_weib2,newdata = list(sex=1))))

```
Mais quand on regarde le graphique, il y a peut être un meilleur modèle :

```{r}
plot(survfit(Surv(time, status) ~ sex, data = kidney), conf.int = FALSE, xlab = 'Temps, t',ylab = bquote(paste(S(t))), col=1:2)
p<-seq(0.01, 0.99, by=.01)
lines(x = predict(fit_weib2, type = "quantile", p = p, newdata=list(sex=0)), y = rev(p),lty=2)
lines(x = predict(fit_weib2, type = "quantile", p = p, newdata=list(sex=1)), y = rev(p),col=2,lty=2)


```



## Comparaison des modèles

### Comparaison "intra-distribution"

Le dataset n'ayant pas beaucoup d'observations, le test de rapport de vraisemblance est à privilégier.
```{r}
anova(fit_weib,fit_weib2)
```

Nous pouvons également regarder les critères AIC et BIC (plus faible est meilleur) :

```{r}
#AIC
extractAIC(fit_weib)
extractAIC(fit_weib2)
#BIC
extractAIC(fit_weib,k=log(nrow(kidney)))
extractAIC(fit_weib2,k=log(nrow(kidney)))
```

Tous les critères indiquent que l'ajustement sur la variable sex permettent d'améliorer les performances du modèle.


### Comparaison "inter-distribution"

#### Comparaison modèles emboités

Le modèle exponentiel correspond au modèle de Weibull pour $\sigma=1$. Ces 2 modèles sont donc emboités et nous pouvons réaliser le test de rapport de vraisemblance.

```{r}
anova(fit_exp,fit_weib)
```

Regardons également les autres critères :

```{r}
#AIC
extractAIC(fit_exp)
extractAIC(fit_weib)
#BIC
extractAIC(fit_exp,k=log(nrow(kidney)))
extractAIC(fit_weib,k=log(nrow(kidney)))
```

Dans tous les cas, les critères indique que le modèle de Weibull n'est pas meilleur que le modèle exponentiel. Le modèle exponentiel, plus simple, sera donc à privilégier.





#### Comparaison modèles non-emboités

Le rapport de vraisemblance n'est plus valable dans ce cas. Utilisons donc les autres critères :

```{r}
k=log(nrow(kidney))
data.frame(model=c("Exponentiel","Weibull","log-normal","log-logistique"),
           AIC=c(extractAIC(fit_exp)[2],extractAIC(fit_weib)[2],extractAIC(fit_logNorm)[2],extractAIC(fit_logLogi)[2]),
           BIC=c(extractAIC(fit_exp,k=k)[2],extractAIC(fit_weib,k=k)[2],extractAIC(fit_logNorm,k=k)[2],extractAIC(fit_logLogi,k=k)[2]))
```

Le modèle log-normal a le meilleur AIC, alors que le modèle exponentiel a le meilleur BIC. Cependant, les différences sont très faibles. Comme précédemment, le modèle le plus simplte (exponentiel) sera donc à favoriser.


Cependant, en prennant en compte un ajustement sur la variable sex, le modèle log-normal sera à privilégier.

```{r}
fit_exp2<-survreg(Surv(time,status) ~ sex, kidney,dist="exponential")
fit_logNorm2<-survreg(Surv(time,status) ~ sex, kidney,dist="lognormal")
fit_logLogi2<-survreg(Surv(time,status) ~ sex, kidney,dist="loglogistic")
k=log(nrow(kidney))
data.frame(model=c("Exponentiel","Weibull","log-normal","log-logistique"),
           AIC=c(extractAIC(fit_exp2)[2],extractAIC(fit_weib2)[2],extractAIC(fit_logNorm2)[2],extractAIC(fit_logLogi2)[2]),
           BIC=c(extractAIC(fit_exp2,k=k)[2],extractAIC(fit_weib2,k=k)[2],extractAIC(fit_logNorm2,k=k)[2],extractAIC(fit_logLogi2,k=k)[2]))
```




## Simulations


Prenons l'exemple de la distribution exponentielle avec un intercept $-log(\lambda)$ égal à 5, dont La distribution f(t) peut être affichée avec :

```{r}
curve(dexp(x,exp(-5)),0,500)
```

Générons des temps de survie selon ce modèle :

```{r}
set.seed(1)
x<-rexp(1000,exp(-5)) #génération de 1000 valeurs selon cette distribution
hist(x,breaks=100,freq=F)
curve(dexp(x,exp(-5)),add=T) #rajouter la distribution théorique sur l'histogramme
```

Cependant, pour réaliser une étude de simulation, il ne faut également pas oublier de générer des temps de censure !

```{r}
set.seed(1)
T<-rexp(500,exp(-5))
cens<-rexp(500,exp(-6)) #paramètres à changer en fonction du taux de censure désiré, potentiellement à regarder en terme analytique
Y<-pmin(T,cens) #obtenir les temps min pour chaque observation entre censure et temps d'évènement
delta<-1*I(T<cens) #Indicatrice d'évènement 1 si temps d'évènement < temps de censure, 0 sinon
summary(fit<-survreg(Surv(Y,delta) ~ 1,dist="exponential"))
print("Simulated intercept: 6")
print(paste0("Estimated intercept: ",coef(fit)," with 95% confidence interval between ",confint(fit)[1]," and ",confint(fit)[2]))
```

La valeur estimée est loin de la valeur théorique. Cependant, il faut se rappeler de la définition de l'intervalle de confiance qui contient la valeur théorique que dans 95% des cas !
Pour vérifier la performance du modèle, il faut réaliser de nombreuses fois ce processus et vérifier que la distribution des paramètres est bien centrée sur les paramètres théoriques (simulés) :

```{r}
check<-rep(0,1000)
for(i in 1:1000){
  set.seed(i)
  T<-rexp(500,exp(-5))
  cens<-rexp(500,exp(-6)) #paramètres à changer en fonction du taux de censure désiré, potentiellement à regarder en terme analytique
  Y<-pmin(T,cens) #obtenir les temps min pour chaque observation entre censure et temps d'évènement
  delta<-1*I(T<cens) #Indicatrice d'évènement 1 si temps d'évènement < temps de censure, 0 sinon
  fit<-survreg(Surv(Y,delta) ~ 1,dist="exponential")
  if(i==1) print(summary(fit))
  CI<-confint(fit)
  check[i]<-ifelse(5>=CI[1] & 5<=CI[2],1,0)
}
paste0(mean(check)*100,"% des IC95% contiennent la valeur théorique")
```

L'intervalle de confiance à 95% contient la valeur théorique dans ~95% des simulations, ce qui est le résultat attendu.

Cette procédure peut être utilisée pour faire du calcul d'effectif nécessaire lorsqu'il n'y a pas de formule analytique ou vérifier les performances d'un nouveau développement statistique. A titre d'exemple, avec le modèle exponentiel (pour lequel il existe une formule établie, à privilégier aux simulations !), supposons que l'on suppose un coefficient de 2 associé à une variable explicative équitablement répartie dans la population :


```{r}
N<-500 #taille de la population
signif<-rep(0,1000)
for(i in 1:1000){
  set.seed(i)
  X<-sort(rep(0:1,N/2))
  T<-rexp(N,exp(-(5+0.5*X)))
  cens<-rexp(N,exp(-6)) #paramètres à changer en fonction du taux de censure désiré, potentiellement à regarder en terme analytique
  Y<-pmin(T,cens) #obtenir les temps min pour chaque observation entre censure et temps d'évènement
  delta<-1*I(T<cens) #Indicatrice d'évènement 1 si temps d'évènement < temps de censure, 0 sinon
  fit<-survreg(Surv(Y,delta) ~ X,dist="exponential")
  CI<-confint(fit)[2,]
  signif[i]<-ifelse(summary(fit)$table[2,4]<0.05,1,0)
}
paste0("Le coefficient est statistiquement significatif dans ",mean(signif)*100,"% des simulations (= puissance)")
```

La puissance est $>$ 99% ! Mais si nous dimunuont l'effectif :

```{r}
N<-100 #taille de la population
signif<-rep(0,1000)
for(i in 1:1000){
  set.seed(i)
  X<-sort(rep(0:1,N/2))
  T<-rexp(N,exp(-(5+0.5*X)))
  cens<-rexp(N,exp(-6)) # paramètres à changer en fonction du taux de censure désiré, potentiellement à regarder en terme analytique
  Y<-pmin(T,cens) #obtenir les temps min pour chaque observation entre censure et temps d'évènement
  delta<-1*I(T<cens) # Indicatrice d'évènement 1 si temps d'évènement < temps de censure, 0 sinon
  fit<-survreg(Surv(Y,delta) ~ X,dist="exponential")
  CI<-confint(fit)[2,]
  signif[i]<-ifelse(summary(fit)$table[2,4]<0.05,1,0)
}
paste0("Le coefficient est statistiquement significatif dans ",mean(signif)*100,"% des simulations (= puissance)")
```

La puissance est beaucoup plus faible ! Une conséquence similaire pourrait être observée si nous diminuions la taille de l'effet.
Pour obtenir la taille idéale, il faut tester différent N jusqu'à ce que la puissance atteigne le seuil désiré (habituellement 80%), ce qui peu prendre beaucoup de temps (de temps de programmation et de calcul), surtout si le modèle est complexe. C'est pourquoi la formule analytique, si elle existe, est a privilégier.





# A vous de jouer

## Statistiques associées aux distributions

Selon les 4 modèles (non-ajusté) :

- Quel est le temps de survie associé à une probabilité de survie de 25% ?
- Extrapolation : Quelle est la probabilité de survie estimée pour t=1000 ?


## Prise en compte d'autres facteurs

Ajustez les modèles sur les variables age, sex et disease.


## Sélection de variable

Comparez les modèles et leurs sous-modèles (avec moins de variables) à l'aide du rapport de vraisemblance et des critères AIC et BIC



