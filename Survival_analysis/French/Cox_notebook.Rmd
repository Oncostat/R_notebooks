---
title: "Travaux pratiques M?thodes semi-param?triques - Mod?le de Cox"
output:
  html_document: 
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_notebook: default
  pdf_document: default
  ---

Ceci est un "notebook". Il permet d'?crire du code au milieu du texte et d'afficher son r?sultat lorsque le document est compil?. Vous pouvez ?galement utiliser les icones en haut ? droite de chaque "chunk" (partie o? se trouve le code), par exemple, la fl?che verte permet de ne recompiler que cette partie.

Ce document est ?crit en language markdown. Les bases qui vous permettront de comprendre la sytaxe sont juste que le "#" permet de d?finir le niveau du titre ("#" = titre 1; "##" = titre 1.1; "###" = titre 1.1.1;...). Le code R est ?crit entre 2 balises, une d'ouverture du chunk et une de fermeture. Exemple:

```{r}
head(cars)
```

Le r?sultat du code s'affiche en dessous si vous compilez le document, ou juste ce chunck en cliquant sur la fl?che verte.

Finalement, lorsque votre document est termin?, vous pouvez obtenir une version clean en cliquant sur le bouton "preview" ou en tapant *Ctrl+Shift+K*. Un fichier de type html se trouve maintenant ? c?t? de votre fichier Rmd, que vous pouvez garder pour vous ou envoyer ? quelqu'un, il suffit d'un navigateur internet (m?me sans connexion) pour pouvoir l'afficher.

Revenons maintenant au cours...



# Rappels: Cr?ation d'un "survival object" dans R

Rechargeons les packages essentiels:

```{r}
library(survival)
library(ggplot2)
library(survminer)
```

Ensuite, utilisons le dataset *veteran* et cr?ons une variable binaire *age55* ?gale ? 0 si l'age $\leq 55$ ans ou est ?gale ? 1 si l'age $\ge 55$ ans.

```{r}
veteran$timeMon<-veteran$time/30.4375 # time in months
veteran$age55<-ifelse(veteran$age<=55, 0, 1) #if age <= 55 years, 0, else 1
head(veteran)
```

Pour obtenir l'estimateur de Kaplan-Meier

```{r}
KM<-survfit(Surv(timeMon,status)~age55,data=veteran)
KM
```

Et pour obtenir la p-value du test du logrank:
```{r}
survdiff(Surv(timeMon,status)~age55,data=veteran)
```

Le nombre de d?cimales pour la p-value est tr?s faible. Pour avoir plus de pr?cision, on peut la recalculer ? la main:

```{r}
logrank0<-survdiff(Surv(timeMon,status)~age55,data=veteran)
1-pchisq(logrank0$chisq, length(logrank0$n) - 1)
```




Pour afficher le graphique avec ggplot2 et survminer (?norm?ment d'options de customisation!):

```{r}
ggsurvplot(KM,
  conf.int = TRUE, #plot confidence interval?
  censor=TRUE,  #Print censor times? (cross)
  linetype=1, #default: 1=continuous line; other options: 2=dotted line, 3=pointed line,...
  main="Veteran survival",
  ylab="Survival probability", #label/title of the Y axis
  xlab="Time since randomization (in months)", #label/title of the X axis
  legend=c(0.85,0.9), # coordinate = % of the image, here = at 85% of the X-axis (right of the plot) and at 90% of Y-axis (top of the plot)
  legend.labs=c("age <= 55 years old","age > 55 years old"),
  pval = TRUE, #print p-value of the logrank test?
  pval.coord=c(20,0.5), #where to print the p-value of the test on the plot (here x=20 and y=0.1)
  risk.table = TRUE, #print the table with the number of patients at risk?
  risk.table.title="Number of patients at risk", #title of the table
  risk.table.y.text = TRUE, #if TRUE, the name of the strata is printed in the table. If FALSE, a line of the color of the strata 
  risk.table.y.text.col = FALSE, #color of the name of the strata similar to curve, here, only one group
  break.time.by=10, #times at which print the number of patients at risk
  ggtheme=theme_bw()
  )
```



# Mod?le de Cox

## Mod?le de Cox univari? avec variable binaire

### Comparaison avec Kaplan-Meier

R?alisons la m?me comparaison que pr?c?dement (en utilisant la variable *age55* que nous avons cr?? plus haut), mais cette fois-ci avec le mod?le de Cox :

```{r}
fitCox0<-coxph(Surv(timeMon,status)~age55,data=veteran)
```

Pour afficher le risque cumul? pour chaque groupe:

```{r}
baselineH<-basehaz(fitCox0,centered=F)
plot(baselineH$time,baselineH$hazard*exp(coef(fitCox0)),type="l",lty=2)
lines(baselineH$time,baselineH$hazard)
legend("topleft",c("< 55 years old",">= 55 years old"),lty=1:2,bty="n")
```


Regardons ce que cela donne au niveau des courbes de survie :

```{r}
plot(KM,main="Veteran survival",ylab="Survival probability",xlab="Time since randomization (in months)",lty=1:2)
survCox00<-survfit(fitCox0,newdata=list(age55=0),conf.int=F)
lines(survCox00,col=2)
survCox01<-survfit(fitCox0,newdata=list(age55=1),conf.int=F)
lines(survCox01,col=2,lty=2)
legend("topright",c("< 55 years old, KM",">= 55 years old, KM","< 55 years old, Cox",">= 55 years old, Cox"),lty=c(1,2,1,2),col=c(1,1,2,2))
```

Le mod?le de Cox reposant sur des hypoth?ses (proportionalit? des risques et log-lin?arit?, cf ci-dessous), il est moins souple que l'estimateur de Kaplan-Meier. Cependant, un mod?le trop souple est souvent difficile ? interpr?ter et risque d'?tre trop ajust? aux donn?es, extrapolant moins bien sur de nouvelles donn?es (moins bonne pr?dictions) : c'est le ph?nom?ne de sur-apprentissage du ? une sur-param?terisation.
D'autre part, le mod?le de Cox a l'avantage par rapport ? l'estimateur de Kaplan-Meier de pouvoir consid?rer des variables continues, des relations non-lin?aires,...



### Comparaison avec le logrank

R?cup?rons les statistiques de test:

```{r}
summary(fitCox0)
cat("\n Print coefficient and p-value with more precision: \n \n") # \n = end of a line (use here to add blank lines)
summary(fitCox0)$coef
```

*Que constate-t-on ?*
La p-value (issue du test de Wald) est tr?s proche de celle du logrank ! Logique car ces tests sont asymptotiquement ?quivalents !

*La fonction donne diff?rentes statistiques de test ? la fin :*
- La statistique du test du rapport de vraisemblance, la plus robuste aux faibles effectifs, mais n?cessite d'estimer les param?tres de 2 mod?les pour estimer la pertinence d'une variable
- La statistique du test de Wald est celle indiqu?e au dessus, car la plus couramment fournie dans tous les mod?les (ex: GLM, survie param?trique,...)
- La statistique du test du score est exactement celle du test du logrank (car c'est le m?me test)
 
*Quelle est la signification de ce test ?*
Elle correspond ? la comparaison du mod?le par rapport ? un mod?le "vide". En univari?, elle correspond au test de la pertinence d'introduire la variable. En multivari?, elle correspond au test de la pertinence d'introduire toutes les variables du mod?le par rapport ? un mod?le vide.


*Logrank ou Cox ?*
Le logrank est le test de base le plus connu pour comparer 2 groupes. Mais il ne donne pas d'indicateur pour quantifier l'importance de cette variable. 
Le mod?le de Cox fourni cet indicateur par le hazard ratio (HR) qui s'interpr?te comme la multiplication du risque si l'on est dans la cat?gorie 1 par rapport ? la cat?gorie 0. Dans les publications, cet HR est celui pr?sent? sur les graphiques de Kaplan-Meier avec la p-value du logrank.


### Proportionalit? des risques

Le mod?le de Cox repose sur l'hypoth?se de proportionalit? des risques, le risque chez les plus de 55 ans est le risque chez les moins de 55 ans (baseline hazard) multipli? par le HR, quel que soit le temps. Nous pouvons le tester ? partir des r?sidus de Schoenfeld avec la fonction *cox.zph* :

```{r}
cox.zph(fitCox0)
```

Et la repr?sentation graphique :

```{r}
plot(cox.zph(fitCox0))
```
Attention : si plusieurs variables sont pr?sentes, il faudra faire une fen?tre graphique pouvant contenir tous les graphiques (ex: si 4 variables, utiliser *par(mfrow=c(2,2))* pour avoir 4 cases) ou n'en demander qu'un (ex : pour la 1?re variable, utiliser *plot(cox.zph(fitCox0)[1])*).


*Comment interpr?te-t-on ce test ?*


*Que faire si l'hypoth?se de proportionalit? des risques n'est pas respect?e ?*
L'une des solutions les plus courantes est de consid?rer que la valeur du HR n'est pas constante dans le temps, en rajoutant par exemple une int?raction avec le temps.


## Effet d?pendant du temps et variable d?pendante du temps


### Effet d?pendant du temps

Supposons que l'hypoth?se de proportionalit? des risques ne tient pas pour HR pr?c?dent. Afin de rajouter une int?raction avec le temps, nous pouvons utiliser la fonction *tt* (time transform) dans la fonction *coxph* :

```{r}
summary(fitCox1<-coxph(Surv(timeMon,status)~age55+tt(age55),data=veteran,tt=function(x,t,...) x*t))
```

Ici, nous avons rajout? une simple interation entre notre variable et le temps, i.e., ? chaque temps, *tt(age55)* vaut 0 si *age55* vaut 0, et elle vaut *t* si *age55* vaut 1. Le 1er HR correspond ? la variable *age55* alors que le second correspond ? cette variable transform?e. Nous pouvons imaginer des relations plus complexes telles qu'une transformation logarithmique :

```{r}
summary(fitCox2<-coxph(Surv(timeMon,status)~age55+tt(age55),data=veteran,tt=function(x,t,...) x*log(t)))
```

Ou m?me encore plus complexe, en utilisant des splines :
```{r}
summary(fitCox3<-coxph(Surv(timeMon,status)~age55+tt(age55),data=veteran,tt=function(x,t,...) pspline(x*t)))
```

Mais attention ? la complexification : cela n'am?liore pas toujours les performances du mod?le et cela devient tr?s vite difficile ? interpr?ter !


### Variable d?pendante du temps (non abord?e dans ce TP)

Ce cas diff?re du 1er dans le sens o? la valeur d'une variable peut changer au cours du temps (d?part/arr?t de traitement, nombre de grosses, poids,...), mais le HR peut lui ?tre constant dans le temps. Dans ce cas, les 2 m?thodes les plus communes sont:

* D?couper le suivi de chaque patient en fonction de la derni?re valeur observ?e
* Analyse du landmark






## Mod?le de Cox univari? avec variable cat?gorielle

A vous de jouer ! Refaites les m?mes analyses que pr?c?demment avec la variable *celltype*. Attention ! Si votre variable est une variable cat?gorielle avec les modalit?s 0, 1, 2,..., ne pas oublier de la transformer en factor ! (sinon elle sera prise en compte comme une variable continue)

### Comparaison avec Kaplan-Meier

```{r}

```


### Comparaison avec le logrank

```{r}

```


### Proportionalit? des risques

```{r}

```



## Mod?le de Cox univari? avec variable continue

### Comparaison avec Kaplan-Meier et logrank

Lorsque la variable est continue, l'estimation de Kaplan-Meier nous donnerait une courbe par valeur, chaque courbe ?tant ? 1 jusqu'? ce que l'?v?nement se produise, puis tomberait directement ? 0. De ce fait, il n'est donc ?galement pas possible d'utiliser le test du logrank.
Le mod?le de Cox en revanche permet de prendre en compte ce type de variable. Dans ce cas, on teste si la variation de risque lorsque la valeur de la variable test?e augmente de 1 est diff?rente de (HR diff?rent de 1).

Essayons cette fois-ci avec l'?ge en continu :

```{r}
summary(fitCoxAge<-coxph(Surv(timeMon,status)~age,data=veteran))
```


### Proportionalit? des risques

```{r}
cox.zph(fitCoxAge)
```


### Log-lin?arit?

#### D?finition

Pour un HR de 1.25 :

* lorsque la variable est ?gale ? 0 ($HR=exp(log(1.25)*0)=1$), le risque est la baseline hazard
* lorsque la variable est ?gale ? 1 ($HR=exp(log(1.25)*1)=1.25$), le risque est la baseline hazard multipli? par 1.25
* lorsque la variable est ?gale ? 1 ($HR=exp(log(1.25)*2)=1.56$), le risque est la baseline hazard multipli? par 1.56
* lorsque la variable est ?gale ? 1 ($HR=exp(log(1.25)*3)=1.95$), le risque est la baseline hazard multipli? par 1.95
* ...

Sur l'?chelle logarithmique, il y a lin?arit? (le log du risque est multipli? par log(HR) pour chaque augmentation de la valeur de la variable de 1) : c'est l'hypoth?se de log-lin?arit?. Cette hypoth?se peut ?tre tr?s forte, par exemple, l'augmentation de risque de cancer du sein entre 18 et 19 ans est probablement plus faible qu'entre 55 et 56 ans. 


#### V?rification de l'hypoth?se de log-lin?arit?

Il n'existe pas de test faisant autant le consensus que celui pour les r?sidus de Shoenfoeld.

Elle peut ?tre v?rifi?e en utilisant les r?sidus de martingale :

```{r}
resMart<-residuals(fitCoxAge,"martingale")
plot(veteran$age,resMart,xlab="Age",ylab="Martingale residuals")
lines(lowess(veteran$age,resMart),col=2)
abline(h=0)
```

Les r?sidus de martingale sont asym?triques (car compris entre $-\infty$ et $+1$), pouvant ?craser la courbe et compliquer l'interpr?tation. Les r?sidus de la d?viance sont une version "sym?tris?e" des r?sidus de martingale, dont les valeurs sont centr?es sur 0, permettant de mieux appr?cier les tendances des r?sidus :

```{r}
resDev<-residuals(fitCoxAge,"deviance")
plot(veteran$age,resDev,xlab="Age",ylab="Deviance residuals")
lines(lowess(veteran$age,resDev),col=2)
abline(h=0)
```

Aucune tendance particuli?re ne se d?gage, l'hypoth?se de log-lin?arit? semble ?tre respect?e.

Une derni?re possibilit? est d'introduire un effet non-lin?aire et de le comparer au mod?le lin?aire. Utilisons ici des splines :
```{r}
summary(fitCoxAgeSp<-coxph(Surv(timeMon,status)~pspline(age),data=veteran))
```

Comparons les effets de fa?on graphique:
```{r}
pred0<-predict(fitCoxAge,type="terms",se.fit=TRUE,terms=1)
pred1<-predict(fitCoxAgeSp,type="terms",se.fit=TRUE,terms=1)
plot(sort(veteran$age),exp(pred1$fit)[order(veteran$age)],type='l',main=" Age Hazard Ratio",ylab="Hazard Ratio",xlab='Age',col=2)#,ylim=c(0,min(c(max(exp(pred0$fit+1.96*pred0$se)),max(exp(pred1$fit+1.96*pred1$se)))))
lines(sort(veteran$age),exp(pred1$fit+1.96*pred1$se)[order(veteran$age)],lty=2,col=2)
lines(sort(veteran$age),exp(pred1$fit-1.96*pred1$se)[order(veteran$age)],lty=2,col=2)
lines(sort(veteran$age),exp(pred0$fit)[order(veteran$age)])
lines(sort(veteran$age),exp(pred0$fit+1.96*pred0$se)[order(veteran$age)],lty=2)
lines(sort(veteran$age),exp(pred0$fit-1.96*pred0$se)[order(veteran$age)],lty=2)
abline(h=1,lty=3)
legend("topright",c("Log-linear assumption","Spline"),col=1:2,bty="n",lty=1)
```
La bande de la spline recouvre l'estimation de la relation log-lin?aire. On peut supposer que l'hypoth?se de log-lin?arit? semble ?tre respect?e.


#### Hypoth?se de log-lin?arit? non v?rifi?e

Dans le cas o? cette hypoth?se ne serait pas valide, plusieurs solutions sont possibles :

* cat?goriser la variable continue
* utiliser une relation non-lin?aire

En g?n?ral, aucune des 2 n'est ad?quate :

* la cat?gorisation augmente le nombre de param?tres ? estimer. De plus, lorsqu'elle est trop "grossi?re" (ex: ?ge $\leq 55$ ans), une relation peut ?tre annul?e, ex : la relation du risque de cancer du sein en fonction de l'?ge a une forme en U (fort risque chez les jeunes femmes et chez les plus ?g?e), la cat?gorisation ?ge $\leq 50$ ans tombe dans le bas du U. La relation moyenne entre les 2 bras du U est donc nulle, car la moyenne du 1er groupe et celle du 2?me sont au milieu de chaque bras. Tirant un trait entre ces 2 points, nous avons une relation nulle, le HR sera proche de 1. Si cette cat?gorisation est trop "fine", de nombreuses cat?gories peuvent ne pas contenir d'?v?nements (ou tr?s peu), posant des probl?mes d'estimation.
* la forme non-lin?aire est plus difficile ? interpr?ter car moins naturelle (logarithme de l'?ge ?) ou plus complexe (ex: utilisation de spline). Dans le second cas, elle peut entra?ner du sur-apprentissage.

Il est donc n?cessaire de raisonner avec parcimonie. Il est possible de r?aliser plusieurs analyses de sensibilit?, mais attention tout de m?me ? la probl?matique de multiplicit? des tests : quand on cherche, on trouve, mais il s'agit peut ?tre du hasard... Le plus souvent, un effet mis en ?vidence en testant diff?rents mod?les avec de nombreuses cat?gorisations diff?rentes est peu reproductible d'une ?tude ? l'autre, car il sera le resultat d'une trop grande ad?quation aux donn?es (sur-apprentissage).




# S?lection de mod?le

## Mod?les emboit?s

Comme pr?cis? pr?c?demment, les tests du score et de Wald sont des approximation du
Lorsque l'on compare 2 mod?les et l'un est un sous-mod?le du 1er, ils sont dis "emboit?s". Par exemple :
```{r}
mod0<-coxph(Surv(timeMon,status)~age,data=veteran)
mod1<-coxph(Surv(timeMon,status)~age+karno,data=veteran)
```

Le test de rapport de vraisemblance peut ?tre appliqu? (le mod1 doit ?tre celui avec le plus de param?tres) :
```{r}
lrt0<-mod0$loglik[2] #get the loglikelihood of the smaller model
lrt1<-mod1$loglik[2] #get the loglikelihood of the larger model
difddl<-length(mod1$coef)-length(mod0$coef) #number of degrees of freedom for the test
chi<--2*lrt0+2*lrt1 #chi square statistic
p<-1-pchisq(chi,difddl)
p
```

Ici, la variable *karno* apporte beaucoup d'information (p = `r p`) et doit ?tre conserv?e.
La variable *age* doit-elle ?tre conserv?e ?
```{r}
mod0<-coxph(Surv(timeMon,status)~karno,data=veteran)
mod1<-coxph(Surv(timeMon,status)~age+karno,data=veteran)
lrt0<-mod0$loglik[2] #get the loglikelihood of the smaller model
lrt1<-mod1$loglik[2] #get the loglikelihood of the larger model
difddl<-length(mod1$coef)-length(mod0$coef) #number of degrees of freedom for the test
chi<--2*lrt0+2*lrt1 #chi square statistic
p<-1-pchisq(chi,difddl)
p
```





## Mod?les non-emboit?s

Si 2 mod?les diff?rent par la forme fonctionnelle d'une ou plusieurs variables. Prenons par exemple les mod?les avec les diff?rentes formes fonctionnelles des interactions entre l'?ge et le temps.
Dans ce cadre, les crit?res les plus utilis?s sont l'Akaike Information Criterion (AIC) et le Bayesian Information Criterion (BIC), en fonction de l'objectif du mod?le. Pour ces 2 crit?res, une plus faible valeur corresponds ? un meilleur mod?le.

```{r}
AIC(mod0)
AIC(mod1)
BIC(mod0)
BIC(mod1)
```

Ils sont en g?n?ral coh?rents. Lorsque ce n'est pas le cas, il faut choisir selon si l'on consid?re que le "vrai" mod?le se trouve parmis ceux test?s (BIC), ou si l'on suppose qu'aucun mod?le n'est vrai et que nous souhaitons s?lectionner le moins mauvais (AIC).

Reprenons l'exemple de la comparaison d'un effet non-log-lin?aire ? un effet log-lin?aire :
```{r}
AIC(fitCoxAge)
AIC(fitCoxAgeSp)
BIC(fitCoxAge)
BIC(fitCoxAgeSp)
```

Ici, nous avons un d?sacord entre ces 2 crit?res. Cependant, la diff?rence est faible, il est donc plus raisonnable de choisir le mod?le le plus interpr?table, d'autant plus que la forme de la spline est tr?s influenc?e par ses extr?mit?s, pour lesquelles nous avons peu de confiance en leurs tendances (du fait du faible nombre d'observations pour les ?ges les plus faibles et les plus avanc?s, qui s'observe par l'?largissement de la bande de confiance).

## Note sur la grande dimension

Lorsque le nombre de variables est grand, le nombre de mod?les possible est ?galement grand. La s?lection pas ? pas permet de ne pas avoir ? tester tous les mod?les possibles (ce qui prendrait trop de temps), mais ce n'est pas une strat?gie stable. En partant de diff?rentes combinaisons de variables, le mod?le final s?lectionn? peut ?tre diff?rent. Simulons un jeu de donn?es avec 1 intercept ? 10, 46 variables n'ayant aucun effet, et 55 autres ayant un effet sur la r?ponse. R?alisons une s?lection pas ? pas avec l'AIC, en partant de 2 mod?les diff?rents :

```{r}
set.seed(123)
n<-150 #number of observations
betas<-c(10,2,2,0.5,0.5,rep(0,46),rnorm(50,1,5)) #Effect of each covariate
stepX<-sapply(1:100,function(x)rnorm(n)) #Generate the 100 independent random gaussian variables
stepY<-rnorm(n,cbind(rep(1,n),stepX)%*%betas,0.5)
stepData<-data.frame(y=stepY,x=stepX)
colnames(stepData)<-c("y",paste0("x",1:100))
library(MASS)
#fit linear model
fit0<-lm(y~1,data=stepData) #NULL model
fit1<-lm(y~.,data=stepData) #Model with all covariates
fit2<-lm(y~x1+x18+x35,data=stepData) #first starting model
#both (backward and forward) stepwise selection from the model fit2
a<-names(stepAIC(fit2,direction="both",trace=F,
                scope = list(upper = fit1, lower = fit0))$coef) #variables in the final model
#both (backward and forward) stepwise selection from the model fit3
fit3<-lm(y~x15+x27+x85,data=stepData) #second starting model
b<-names(stepAIC(fit3,direction="both",trace=F,
                scope = list(upper = fit1, lower = fit0))$coef) #variables in the final model
#difference between the variables selected according to the starting model
setdiff(a,b) #"x18" "x43" "x92" "x9"  "x33"
setdiff(b,a) #"x6"  "x5"  "x7"  "x46" "x16"

```

Les mod?les s?lectionn?s sont compl?tement diff?rents... Lorsque vous vous retrouvez face ? cette situation :

* testez plusieurs points de d?part pour v?rifier la stabilit? de la proc?dure
* estimez tous les param?tres possibles et comparez les avec l'AIC ou le BIC (long) ou 2 ? 2 avec le test de rapport de vraisemblance. Cette 2?me solution est encore plus long et plus complexe ? mettre en oeuvre, mais vous avez une r?gle de d?cision (p-value), contrairement ? l'AIC et le BIC (la diff?rence entre un AIC de 30012 et un de 30015 est-elle significative ?)
* utilisez des m?thodes de s?lection pour la grande dimension (en dehors du scope de ce cours : plus complexes et avec des r?sultats potentiellement instables -> maitrisez la th?orie avant de les utiliser)




# A vous de jouer:

Mod?le de Cox multivari? avec plusieurs variables.

## Ajuster un mod?le de Cox univari? sur la variable cell

* Que signifie le test de rapport de vraisemblance (LR-test) ?
* Comment est-il construit ?
* Comment l'interpr?ter ?

```{r}

```


## Ajuster un mod?le de Cox multivari? sur les variables *age* et *prior*

```{r}

```

Calculer la (log)vraisemblance du mod?le et le nombre de ddl

```{r}

```




## Ajuster un mod?le de Cox multivari? sur les variables *age*, *prior* et *celltype*

```{r}

```

Calculer la (log)vraisemblance du mod?le et le nombre de ddl

```{r}

```


## Calculer la statistique du test de rapport de vraisemblance

```{r}

```

## Quelle loi suit cette statistique ?


## Conclure sur la base de ce test



## Quelle serait la conclusion si on aurait utilis? le crit?re AIC ? BIC?

```{r}

```










